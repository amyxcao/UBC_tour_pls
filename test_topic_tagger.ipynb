{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import AzureOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "THEME_TAGS = [\n",
    "    \"symbolism\", \"technique\", \"mythical_creatures\", \"landscapes\", \"nature\"\n",
    "]\n",
    "TIME_PERIOD_TAGS = [\n",
    "    \"tang\", \"song\", \"yuan\", \"ming\", \"qing\"\n",
    "]\n",
    "ART_MEDIUM_TAGS = [\n",
    "    \"silk\", \"cermanics\", \"paintings\"\n",
    "]\n",
    "\n",
    "SECTION_TYPE_TAGS = [\n",
    "    \"artist\", \"historical_context\", \"artwork\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(text, header):\n",
    "    return f\"\"\"\n",
    "You are a museum content classifier. Based on the exhibit description below, assign the most appropriate value for each of the following fields using only the given list of tags, you may select one, more than one, or none for each respective category. \n",
    "\n",
    "Respond only with a JSON object using the tag values provided.\n",
    "\n",
    "Use all of this context when making your decision.\n",
    "\n",
    "---\n",
    "\n",
    "**Header**: {header}\n",
    "**Text**: {text}\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Themes** (choose one): \n",
    "{json.dumps(THEME_TAGS)}\n",
    "\n",
    "**Time Period** (choose one): \n",
    "{json.dumps(TIME_PERIOD_TAGS)}\n",
    "\n",
    "**Geographic Region** (choose one):\n",
    "{json.dumps(ART_MEDIUM_TAGS)}\n",
    "\n",
    "---\n",
    "\n",
    "Respond with JSON in this format:\n",
    "{{\n",
    "  \"themes\": [\"ThemeTagHere\"],\n",
    "  \"time_period\": [\"TimePeriodTagHere\"],\n",
    "  \"art_medium\": [\"ArtMediumTagHere\"]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "def clean_json_string(s: str) -> str:\n",
    "    # Remove markdown code fences and language specifiers\n",
    "    s = s.strip()\n",
    "    if s.startswith(\"```\"):\n",
    "        # Remove starting and ending fence.\n",
    "        s = s.lstrip(\"`\").rstrip(\"`\").strip()\n",
    "        # Remove language specifier if it exists (e.g. \"json\")\n",
    "        s = re.sub(r\"^json\\s*\", \"\", s, flags=re.IGNORECASE)\n",
    "    return s\n",
    "\n",
    "def tag_chunk(text, header):\n",
    "    prompt = create_prompt(text, header)\n",
    "    client = AzureOpenAI(\n",
    "        api_version=os.environ.get(\"API_VERSION\", \"2024-12-01-preview\"),\n",
    "        azure_endpoint=os.environ.get(\n",
    "            \"AZURE_OPENAI_ENDPOINT\", \"https://openai-ai-museum.openai.azure.com/\"\n",
    "        ),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=16384,\n",
    "        temperature=0,\n",
    "        model=os.environ.get(\"AZURE_OPENAI_DEPLOYEMENT\", \"gpt-4o\"),\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    # Collect streamed content\n",
    "    collected_response = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices:\n",
    "            delta = chunk.choices[0].delta\n",
    "            collected_response += delta.content if hasattr(delta, \"content\") and delta.content is not None else \"\"\n",
    "    \n",
    "    # Clean the response from markdown formatting\n",
    "    clean_response = clean_json_string(collected_response)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(clean_response)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Could not decode JSON:\", clean_response)\n",
    "        return {}\n",
    "\n",
    "def topic_tagger(input_file, output_dir=None):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        input_file (_type_): _description_\n",
    "        output_dir (_type_, optional): _description_. Defaults to None.\n",
    "    \"\"\"\n",
    "    # Load chunked JSON\n",
    "    with open(input_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_file = input_file  # Overwrite input file if no output directory specified.\n",
    "    else:\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        output_file = os.path.join(output_dir, os.path.basename(input_file))\n",
    "\n",
    "        \n",
    "    for item in data.values(): \n",
    "        chunk_text_list = item.get('text', '')\n",
    "        chunk_text = \" \".join(chunk_text_list)\n",
    "        header = item.get('header', '')\n",
    "        llm_tags = tag_chunk(chunk_text, header)\n",
    "        \n",
    "        # update tags in JSON\n",
    "        item['time_period'] = llm_tags['time_period']\n",
    "        item['art_medium'] = llm_tags['art_medium']\n",
    "        item['themes'] = llm_tags['themes']\n",
    "\n",
    "    # Save updated JSON\n",
    "    with open(output_file, \"w\", encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_tagger(\"output/Objectifying_China/preprocessed/en_contents_chunked_sample2.json\", \n",
    "             \"output/Objectifying_China/tagged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
