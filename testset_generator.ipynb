{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "azure_configs = {\n",
    "    \"base_url\": \"https://openai-ai-museum.openai.azure.com/\", \n",
    "    \"embedding_deployment\": \"text-embedding-3-large\",\n",
    "    \"embedding_name\": \"text-embedding-3-large\",\n",
    "    \"model_name\": \"gpt-4o\",\n",
    "    \"api_version\": \"2024-10-21\",  \n",
    "    \"model_deployment\": \"gpt-4o\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'silk.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m file_path = \u001b[33m\"\u001b[39m\u001b[33msilk.txt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Read the text file content\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m      9\u001b[39m     text_content = file.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\softwares\\miniconda3\\envs\\aiha\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:327\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    322\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    325\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'silk.txt'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_path = \"silk.txt\"\n",
    "\n",
    "# Read the text file content\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "generator_llm = LangchainLLMWrapper(AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    azure_endpoint=azure_configs[\"base_url\"],\n",
    "    azure_deployment=azure_configs[\"model_deployment\"],\n",
    "    model=azure_configs[\"model_name\"],\n",
    "    validate_base_url=False,\n",
    "))\n",
    "\n",
    "# init the embeddings for answer_relevancy, answer_correctness and answer_similarity\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(AzureOpenAIEmbeddings(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    azure_endpoint=azure_configs[\"base_url\"],\n",
    "    azure_deployment=azure_configs[\"embedding_deployment\"],\n",
    "    model=azure_configs[\"embedding_name\"],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m doc = Document(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m         page_content=\u001b[43mtext_content\u001b[49m, \n\u001b[32m      3\u001b[39m         metadata={\u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: file_path,\n\u001b[32m      4\u001b[39m                 \u001b[38;5;66;03m#   \"summary\": \"This document is about silk\",\u001b[39;00m\n\u001b[32m      5\u001b[39m                 \u001b[38;5;66;03m#   \"headlines\": \"Silk\", \u001b[39;00m\n\u001b[32m      6\u001b[39m                   }\n\u001b[32m      7\u001b[39m     )\n",
      "\u001b[31mNameError\u001b[39m: name 'text_content' is not defined"
     ]
    }
   ],
   "source": [
    "doc = Document(\n",
    "        page_content=text_content, \n",
    "        metadata={\"source\": file_path,\n",
    "                #   \"summary\": \"This document is about silk\",\n",
    "                #   \"headlines\": \"Silk\", \n",
    "                  }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  \n",
    "    chunk_overlap=100, \n",
    "    length_function=len,\n",
    "    add_start_index=True,  \n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying CustomNodeFilter:   0%|          | 0/78 [00:00<?, ?it/s]         Node 3091d034-63b2-4129-8daf-1f7d5f25a715 does not have a summary. Skipping filtering.\n",
      "Node b6e7b946-351a-4a8d-a2a0-fa4c81226e9b does not have a summary. Skipping filtering.\n",
      "Node 2c17e40a-1c01-424f-a388-6c51364a1b85 does not have a summary. Skipping filtering.\n",
      "Node d7e353da-2905-40a6-b006-a27897d8496d does not have a summary. Skipping filtering.\n",
      "Node 16d39a57-4931-449b-bbe3-52c755e089a4 does not have a summary. Skipping filtering.\n",
      "Node 2335d2c4-d481-4c12-abda-f7a3fa6b5342 does not have a summary. Skipping filtering.\n",
      "Node 929b884f-3578-4a31-9798-d35166a5a414 does not have a summary. Skipping filtering.\n",
      "Node a4bd3343-a1b4-4631-bf53-45e73b07a2a9 does not have a summary. Skipping filtering.\n",
      "Node 6b2b4280-1263-441d-a0ba-36cf77e04990 does not have a summary. Skipping filtering.\n",
      "Node aab2e046-65c3-45fa-9485-9def7c0bbe92 does not have a summary. Skipping filtering.\n",
      "Node a9c1a3ac-20b7-4749-ab5b-9f998c4b377e does not have a summary. Skipping filtering.\n",
      "Node cb762305-44bd-413c-86ec-eb4f35015779 does not have a summary. Skipping filtering.\n",
      "Node 74222485-ab2c-4b74-8577-006ecbdeb83c does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  18%|█▊        | 14/78 [00:00<00:02, 25.39it/s]Node abb3627f-6436-4fec-a5b5-d43f35e1ff6f does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  36%|███▌      | 28/78 [00:00<00:01, 48.32it/s]Node 0cf4bd21-4f9c-419d-a28e-4ef2b373a7c9 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  47%|████▋     | 37/78 [00:01<00:01, 33.29it/s]Node 5f8a577e-a396-4547-b478-cb486b0a9ed0 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  59%|█████▉    | 46/78 [00:01<00:00, 40.50it/s]Node 49a5f224-29e4-4748-b6c5-54e43923343f does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  68%|██████▊   | 53/78 [00:01<00:00, 30.83it/s]Node 492afec4-e474-4553-bbea-9b29cab1cc3b does not have a summary. Skipping filtering.\n",
      "Node efc1adf3-4b9e-4cde-bd54-fde579f73620 does not have a summary. Skipping filtering.\n",
      "Generating personas: 100%|██████████| 3/3 [00:01<00:00,  2.01it/s]                                             \n",
      "Generating Scenarios: 100%|██████████| 3/3 [00:25<00:00,  8.49s/it]\n",
      "Generating Samples: 100%|██████████| 12/12 [00:05<00:00,  2.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(chunks, testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mdataset\u001b[49m.to_pandas()\n",
      "\u001b[31mNameError\u001b[39m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "df = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who Stephy Tsui?</td>\n",
       "      <td>[Pictorialhinese Textiles from the UMAG CSolle...</td>\n",
       "      <td>Stephy Tsui is the designer for the publicatio...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What Cixiu Embroidery be about?</td>\n",
       "      <td>[rights reserved. No part of this publication ...</td>\n",
       "      <td>The context does not provide specific informat...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What HKU got to do with them textiles and embr...</td>\n",
       "      <td>[EmbroideryGlossaryBibliographyTextiles illust...</td>\n",
       "      <td>The textiles and embroidery pieces illustrated...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is HKU's connection to the donated textiles?</td>\n",
       "      <td>[pieces were donated by Dr Hui Wai Haan, who t...</td>\n",
       "      <td>The textiles were donated by Dr Hui Wai Haan, ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the connection between kesi silk tapes...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nblocks, and within a set distance ...</td>\n",
       "      <td>Kesi silk tapestry is connected to the Norther...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How calligraphy and traditional Chinese art li...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\ncalligraphy in the Song, Yuan and ...</td>\n",
       "      <td>Calligraphy and traditional Chinese art, such ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How did painting-like textiles incorporate lan...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nfor painting-like textiles. The Yu...</td>\n",
       "      <td>Painting-like textiles incorporated landscapes...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How did the Suzhou School of Embroidery integr...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nstyle and techniques were subseque...</td>\n",
       "      <td>The Suzhou School of Embroidery (Suxiu) artisa...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the process of creating silk tapestry ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nwoven’) was adopted by scholars in...</td>\n",
       "      <td>The process of creating silk tapestry begins w...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How were silk tapestries utilized during the Y...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nFig. 9  \\tFlowers and Garden Rock....</td>\n",
       "      <td>During the Yuan dynasty (1271–1368), silk tape...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How did the unique properties of silk, such as...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\ntechniques and originsSilk refers ...</td>\n",
       "      <td>Silk, with its unique properties such as elast...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is the role of warp threads in the produc...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nwoven’) was adopted by scholars in...</td>\n",
       "      <td>Warp threads in raw silk are first stretched o...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0                                    Who Stephy Tsui?   \n",
       "1                     What Cixiu Embroidery be about?   \n",
       "2   What HKU got to do with them textiles and embr...   \n",
       "3   What is HKU's connection to the donated textiles?   \n",
       "4   What is the connection between kesi silk tapes...   \n",
       "5   How calligraphy and traditional Chinese art li...   \n",
       "6   How did painting-like textiles incorporate lan...   \n",
       "7   How did the Suzhou School of Embroidery integr...   \n",
       "8   What is the process of creating silk tapestry ...   \n",
       "9   How were silk tapestries utilized during the Y...   \n",
       "10  How did the unique properties of silk, such as...   \n",
       "11  What is the role of warp threads in the produc...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [Pictorialhinese Textiles from the UMAG CSolle...   \n",
       "1   [rights reserved. No part of this publication ...   \n",
       "2   [EmbroideryGlossaryBibliographyTextiles illust...   \n",
       "3   [pieces were donated by Dr Hui Wai Haan, who t...   \n",
       "4   [<1-hop>\\n\\nblocks, and within a set distance ...   \n",
       "5   [<1-hop>\\n\\ncalligraphy in the Song, Yuan and ...   \n",
       "6   [<1-hop>\\n\\nfor painting-like textiles. The Yu...   \n",
       "7   [<1-hop>\\n\\nstyle and techniques were subseque...   \n",
       "8   [<1-hop>\\n\\nwoven’) was adopted by scholars in...   \n",
       "9   [<1-hop>\\n\\nFig. 9  \\tFlowers and Garden Rock....   \n",
       "10  [<1-hop>\\n\\ntechniques and originsSilk refers ...   \n",
       "11  [<1-hop>\\n\\nwoven’) was adopted by scholars in...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   Stephy Tsui is the designer for the publicatio...   \n",
       "1   The context does not provide specific informat...   \n",
       "2   The textiles and embroidery pieces illustrated...   \n",
       "3   The textiles were donated by Dr Hui Wai Haan, ...   \n",
       "4   Kesi silk tapestry is connected to the Norther...   \n",
       "5   Calligraphy and traditional Chinese art, such ...   \n",
       "6   Painting-like textiles incorporated landscapes...   \n",
       "7   The Suzhou School of Embroidery (Suxiu) artisa...   \n",
       "8   The process of creating silk tapestry begins w...   \n",
       "9   During the Yuan dynasty (1271–1368), silk tape...   \n",
       "10  Silk, with its unique properties such as elast...   \n",
       "11  Warp threads in raw silk are first stretched o...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
